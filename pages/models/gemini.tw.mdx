# Gemini 入門指南

import { Callout, FileTree } from 'nextra-theme-docs'
import {Screenshot} from 'components/screenshot'
import GEMINI1 from '../../img/gemini/gemini-1.png'
import GEMINI2 from '../../img/gemini/gemini-architecture.png'
import GEMINI3 from '../../img/gemini/gemini-result.png'
import GEMINI4 from '../../img/gemini/gemini-2.png'
import GEMINI5 from '../../img/gemini/gemini-3.png'
import GEMINI6 from '../../img/gemini/gemini-6.png'
import GEMINI7 from '../../img/gemini/gemini-7.png'
import GEMINI8 from '../../img/gemini/gemini-8.png'
import GEMINI9 from '../../img/gemini/pe-guide.png'
import GEMINI10 from '../../img/gemini/prompt-webqa-1.png'
import GEMINI11 from '../../img/gemini/prompt-webqa-2.png'
import GEMINI12 from '../../img/gemini/gemini-few-shot.png'
import GEMINI13 from '../../img/gemini/gemini-few-shot-2.png'

本指南概覽 Gemini 模型家族，並說明如何有效地對它們進行提示詞設計與使用。內容包含：

- 能力與特色
- 提示詞與設計建議
- 典型應用與示例
- 限制與注意事項
- 相關論文與延伸閱讀

## Gemini 簡介

Gemini 是 Google DeepMind 推出的最新高階模型系列，從設計之初就具備多模態能力，能在文字、影像、影片、音訊與程式碼等多種模態間進行跨模態推理。

Gemini 目前主要有三個尺寸版本：

- **Ultra**：最強版本，適合最複雜的任務；
- **Pro**：在各種任務間取捨良好的通用版本；
- **Nano**：針對裝置端、記憶體受限情境的精簡版（例如 Nano‑1 1.8B、Nano‑2 3.25B），由較大型 Gemini 模型蒸餾而來並量化至 4-bit。

根據[技術報告](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)，Gemini 在 32 個基準中的 30 個達到 SOTA 或顯著提升，涵蓋：

- 語言理解與產生
- 程式碼
- 推理與數學
- 多模態推理等

它是第一個在 [MMLU](https://paperswithcode.com/dataset/mmlu)（綜合考試型 benchmark）上達到「human-expert」等級表現的模型，並在 20 個多模態基準上取得最佳成績。
Gemini Ultra 在 MMLU 上達到 90.0%，在 [MMMU benchmark](https://mmmu-benchmark.github.io/)（需要大學程度知識與推理）上達到 62.4%。

Gemini 系列採用 Transformer decoder 架構並搭配多種效率最佳化技巧（例如 [Fast Transformer Decoding: One Write-Head is All You Need](https://arxiv.org/abs/1911.02150)），支援 **32k context length**，可接受文字、影像與音訊交錯輸入，並能輸出文字與影像。

<Screenshot src={GEMINI2} alt="GEMINI2" />

模型訓練資料涵蓋多模態與多語言來源，包括網頁文件、書籍、程式碼、影像、音訊與影片等，並採 joint training 的方式，同時最佳化跨模態與各模態內的能力。

## Gemini 實驗結果概觀

在搭配 [Chain-of-Thought（CoT）提示詞](https://www.promptingguide.ai/techniques/cot) 與 [self-consistency](https://www.promptingguide.ai/techniques/consistency) 等技巧時，Gemini Ultra 的成效特別突出。

技術報告中指出：

- 在 MMLU 上，若只用 greedy decoding，準確率約為 84.0%；
- 採用「不確定性導向的 CoT + 多樣本投票」後（32 筆樣本），可提升到 90.0%；
- 在 GSM8K 小學數學基準上，CoT + self-consistency 可達 94.4%；
- 在 [HumanEval](https://paperswithcode.com/dataset/humaneval) 程式碼補全上，Gemini Ultra 能正確解出 74.4% 題目。

<Screenshot src={GEMINI3} alt="GEMINI3" />

Gemini Nano 在多種任務上也有不錯表現，包括：

- 檢索與事實性（retrieval-related tasks）
- 推理與 STEM
- 程式碼產生
- 多模態與多語言任務

在多語言方面，Gemini 在像 [MGSM](https://paperswithcode.com/dataset/mgsm) 與 [XLSum](https://paperswithcode.com/dataset/xl-sum) 這類多語數學與摘要基準上也展現相當競爭力。

此外，Gemini 模型在 32k context 內查詢資訊時，實驗顯示其能以約 98% 的正確率找回指定內容，對文件檢索與影片理解等用例特別重要。

指令調整版本（instruction‑tuned）的 Gemini 模型在人類評估中，也在指令遵從、創意寫作與安全性等面向有較高偏好度。

## Gemini 多模態推理能力

Gemini 從原生多模態訓練出發，能把語言模型的推理能力與多模態能力結合。它的能力包含（但不限於）：從表格、圖表與圖形中擷取資訊；也能從輸入中辨識更細緻的差異、在時間與空間上彙整脈絡，並整合不同模態的資訊。

Gemini 在許多影像理解任務上（例如高層次物件辨識、細緻轉寫、圖表理解與多模態推理）都能穩定優於既有方法。部分影像理解與產生能力也能跨語言移轉到不同語言（例如用 Hindi、Romanian 等語言產生圖片描述）。

### Text Summarization

雖然 Gemini 是多模態系統，但也具備現代大型語言模型（例如 GPT-3.5、Claude、Llama）常見的能力。以下示範使用 Gemini Pro 做簡單文字摘要任務。我們在 [Google AI Studio](https://ai.google.dev) 中以 `temperature = 0` 測試。

Prompt:
```
Your task is to summarize an abstract into one sentence.

Avoid technical jargon and explain it in the simplest of words.

Abstract: Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body’s immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.
```

Gemini Pro Output:
```
Antibiotics are medicines used to kill or stop the growth of bacteria causing infections, but they don't work against viruses.
```

以下是任務與模型回應（已標示）在 Google AI Studio 中的畫面：

<Screenshot src={GEMINI8} alt="GEMINI8" />

### Information Extraction

以下是另一個分析文字並擷取指定資訊的例子。請注意：這裡使用的是 zero-shot prompting，因此結果不會完美，但模型表現仍相對不錯。

Prompt:
```
Your task is to extract model names from machine learning paper abstracts. Your response is an array of the model names in the format [\"model_name\"]. If you don't find model names in the abstract or you are not sure, return [\"NA\"]

Abstract: Large Language Models (LLMs), such as ChatGPT and GPT-4, have revolutionized natural language processing research and demonstrated potential in Artificial General Intelligence (AGI). However, the expensive training and deployment of LLMs present challenges to transparent and open academic research. To address these issues, this project open-sources the Chinese LLaMA and Alpaca…
```

Gemini Pro Output:
```
[\"LLMs\", \"ChatGPT\", \"GPT-4\", \"Chinese LLaMA\", \"Alpaca\"]
```

### Visual Question Answering

視覺問答（visual question answering）指的是：針對輸入圖片向模型提問。Gemini 模型在圖表、自然影像、迷因等不同類型圖片上，都展現多模態推理能力。以下例子中，我們提供 Gemini Pro Vision（透過 Google AI Studio 使用）一段文字指令與一張圖片，該圖片是本提示詞工程指南的網站截圖。

模型回應：「The title of the website is "Prompt Engineering Guide".」從提問來看應該是正確答案。

<Screenshot src={GEMINI10} alt="GEMINI10" />

以下是另一個使用不同輸入問題的例子。Google AI Studio 允許你透過上方的 `{{}} Test input` 選項測試不同輸入，並在下方表格中加入要測試的 prompts。

<Screenshot src={GEMINI11} alt="GEMINI11" />

你也可以嘗試上傳自己的圖片並提問。據報導，Gemini Ultra 在這類任務上可做到更好的表現；待模型公開後，我們也會再做更多測試。

### Verifying and Correcting

Gemini 也展現很強的跨模態推理能力。以下例子中，左側是教師畫出的物理題解；接著用提示詞引導 Gemini 推理題目並說明學生解法錯在哪裡（如果有），並要求它解題且數學部分用 LaTeX。右側是模型產生的解答，包含對題目與解法的細緻說明。

<Screenshot src={GEMINI1} alt="GEMINI1" />

### Rearranging Figures

以下是技術報告中的另一個例子：Gemini 會產生 matplotlib 程式碼來重新排列子圖（subplots）。多模態提示詞在左上、產生的程式碼在右側，而渲染後的結果在左下。模型同時運用了多項能力：辨識、程式碼產生、對子圖位置做抽象推理，以及指令遵循，來把子圖重新排列到指定位置。

<Screenshot src={GEMINI4} alt="GEMINI4" />

### Video Understanding

Gemini Ultra 在多種 few-shot 影片字幕（captioning）與 zero-shot 影片問答任務上取得 SOTA 成績。以下例子中，模型收到一段影片與文字指令，能分析影片並對情境推理，給出適切回答；此例則是提出建議，說明影片中的人可以如何改善技巧。

<Screenshot src={GEMINI5} alt="GEMINI5" />

### Image Understanding

Gemini Ultra 也能接收 few-shot prompts 並產生圖片。以下例子中，prompt 提供了一組影像與文字交錯的 few-shot 範例：使用者提供兩種顏色資訊與圖片建議；模型再根據 prompt 的最終指令，回應它看到的顏色並提出一些想法。

<Screenshot src={GEMINI6} alt="GEMINI6" />

### Modality Combination

Gemini 也能原生處理音訊與圖片序列。以下例子中，prompt 提供了一段音訊與圖片的序列，模型能回傳一段文字回應，並納入每次互動的脈絡來回答。

<Screenshot src={GEMINI7} alt="GEMINI7" />

### Gemini Generalist Coding Agent

Gemini 也被用來打造通用型 agent：[AlphaCode 2](https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf)。AlphaCode 2 把 Gemini 的推理能力與搜尋、工具使用結合，用於解決競程題目；在 Codeforces 的參賽者中排名前 15%。

## Few-Shot Prompting with Gemini

Few-shot prompting 是一種提示詞方法，用來告訴模型「你想要什麼樣的輸出」。這在你希望輸出符合特定格式（例如 JSON）或特定風格時很有用。Google AI Studio 也在介面中提供了這類能力。以下示範如何在 Gemini 上使用 few-shot prompting。

這裡的目標是用 Gemini 做一個簡單的情緒分類器。第一步是在 Google AI Studio 中點選「Create new」或「+」，建立一個「Structured prompt」。few-shot prompt 會把你的任務指令（描述任務）與你提供的範例合併。下圖示意我們送給模型的指令（上方）與範例（下方）。你可以設定 INPUT／OUTPUT 的文字指示器（indicator）更具描述性；本例以「Text:」作為輸入指示器，並以「Emotion:」作為輸出指示器。

<Screenshot src={GEMINI12} alt="GEMINI12" />

合併後的完整 prompt 如下：

```
Your task is to classify a piece of text, delimited by triple backticks, into the following emotion labels: ["anger", "fear", "joy", "love", "sadness", "surprise"]. Just output the label as a lowercase string.
Text: I feel very angry today
Emotion: anger
Text: Feeling thrilled by the good news today.
Emotion: joy
Text: I am actually feeling good today.
Emotion:
```

接著你可以在「Test your prompt」區塊加入輸入。我們以 `I am actually feeling good today.` 作為輸入，按下「Run」後模型正確輸出 `joy`；如下圖所示：

<Screenshot src={GEMINI13} alt="GEMINI13" />

## 使用 Gemini API 的範例

以下是一段使用 Gemini API 向 Gemini Pro 模型下提示詞的簡單示例。你需要先安裝 `google-generativeai`，並從 Google AI Studio 取得 API Key。這段範例會執行與上面相同的資訊擷取任務。

```python
"""
At the command line, only need to run once to install the package via pip:

$ pip install google-generativeai
"""

import google.generativeai as genai

genai.configure(api_key="YOUR_API_KEY")

# Set up the model
generation_config = {
  "temperature": 0,
  "top_p": 1,
  "top_k": 1,
  "max_output_tokens": 2048,
}

safety_settings = [
  {
    "category": "HARM_CATEGORY_HARASSMENT",
    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
  },
  {
    "category": "HARM_CATEGORY_HATE_SPEECH",
    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
  },
  {
    "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
  },
  {
    "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
  }
]

model = genai.GenerativeModel(model_name="gemini-pro",
                              generation_config=generation_config,
                              safety_settings=safety_settings)

prompt_parts = [
  "Your task is to extract model names from machine learning paper abstracts. Your response is an array of the model names in the format [\\\"model_name\\\"]. If you don't find model names in the abstract or you are not sure, return [\\\"NA\\\"]\n\nAbstract: Large Language Models (LLMs), such as ChatGPT and GPT-4, have revolutionized natural language processing research and demonstrated potential in Artificial General Intelligence (AGI). However, the expensive training and deployment of LLMs present challenges to transparent and open academic research. To address these issues, this project open-sources the Chinese LLaMA and Alpaca…",
]

response = model.generate_content(prompt_parts)
print(response.text)
```

輸出與前面一致：

```
[\"LLMs\", \"ChatGPT\", \"GPT-4\", \"Chinese LLaMA\", \"Alpaca\"]
```

## 參考資料

- [Introducing Gemini: our largest and most capable AI model](https://blog.google/technology/ai/google-gemini-ai/#sundar-note)
- [How it’s Made: Interacting with Gemini through multimodal prompting](https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html)
- [Welcome to the Gemini era](https://deepmind.google/technologies/gemini/#introduction)
- [Prompt design strategies](https://ai.google.dev/docs/prompt_best_practices)
- [Gemini: A Family of Highly Capable Multimodal Models - Technical Report](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)
- [Fast Transformer Decoding: One Write-Head is All You Need](https://arxiv.org/abs/1911.02150)
- [Google AI Studio quickstart](https://ai.google.dev/tutorials/ai-studio_quickstart)
- [Multimodal Prompts](https://ai.google.dev/docs/multimodal_concepts)
- [Gemini vs GPT-4V: A Preliminary Comparison and Combination of Vision-Language Models Through Qualitative Cases](https://arxiv.org/abs/2312.15011v1)
- [A Challenger to GPT-4V? Early Explorations of Gemini in Visual Expertise](https://arxiv.org/abs/2312.12436v2)

# 事實性

LLM 傾向於產生聽起來連貫且具說服力的回應，但有時候可能是捏造的。改進提示詞可以協助模型產生更準確／事實的回應，並降低產生不一致和捏造的回應的機率。

可能的解決方案包括：
- 在上下文中提供真實資料（例如，相關的文章段落或是維基百科條目）以減少模型產生捏造文字的可能性。
- 調整模型的設定，降低多樣性回應的機率，並在不知道答案的情況下指示它承認（例如，「我不知道」）。
- 在提示詞中提供一組可能知道或不知道的問題和回應的例子。

來看一個簡單的例子：

*提示詞：*
```
Q: 什麼是原子？
A: 原子是構成所有事物的微小粒子。

Q: Alvan Muntz 是誰？
A: ?

Q: Kozar-09 是什麼？
A: ?

Q: 火星有多少顆衛星？
A: 兩顆，Phobos 和 Deimos。

Q: Neto Beto Roberto 是誰？
```

*輸出：*
```
A: ?
```

我捏造了 "Neto Beto Roberto" 這個名字，所以模型在這個情況下是正確的。嘗試稍微改變問題，看看你能否讓它運作。根據你至今所學，還有其他不同的方式可以進一步改善。

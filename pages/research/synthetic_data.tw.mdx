# 語言模型合成資料的實務經驗與最佳做法

import {Bleed} from 'nextra-theme-docs'

<iframe width="100%"
  height="415px"
  src="https://www.youtube.com/embed/YnlArBZJHY8?si=ZH3hFzwixUopxU5Z" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
  />

這篇由 Google DeepMind 與多家團隊共同完成的[論文](https://arxiv.org/abs/2404.07503)，系統性整理了「為語言模型打造合成資料」的實務經驗、最佳做法與常見陷阱。

文章聚焦在合成資料的多種應用、挑戰與未來發展方向。隨著近年許多模型效能突破都與合成資料密切相關，這份整理對研究與實務都有參考價值。

我們已經很清楚：給模型更多「高品質資料」，通常就能換來更好的表現。要產生大量合成資料本身不難，真正的難題在於：如何確保這些資料的品質。

論文特別討論了使用合成資料時需要注意的面向，包括：

- 品質與真實性
- 事實正確性與可信度
- 保持語料多樣性與代表性
- 偏誤與公平性
- 隱私與安全

此外，文中也整理了許多相關工作的參考文獻，可作為深入研究此主題的起點。


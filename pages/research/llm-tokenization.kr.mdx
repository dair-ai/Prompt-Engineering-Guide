# LLM 토큰화 (Tokenization)

Andrej Karpathy는 최근 대형 언어 모델(LLM) 토큰화에 관한 새로운 [강의](https://youtu.be/zduSFxRajkE?si=Hq_93DBE72SQt73V)를 발표했습니다. 토큰화는 LLM 훈련에서 중요한 부분을 차지하지만, 이는 자체 데이터셋과 알고리즘(예시., [바이트 페어 인코딩](https://en.wikipedia.org/wiki/Byte_pair_encoding))을 사용하여 토크나이저를 훈련하는 과정을 포함합니다.. 

강의에서 Karpathy는 GPT 토크나이저를 처음부터 구현하는 방법을 가르칩니다. 또한 토큰화에서 비롯된 이상한 동작들에 대해서도 논의합니다.

!["LLM Tokenization"](../../img/research/tokenization.png)

*그림 출처: https://youtu.be/zduSFxRajkE?t=6711*

다음은 위 리스트를 텍스트로 옮긴 것입니다:

- 왜 LLM은 단어를 정확히 쓸 수 없나요? 토큰화.
- 왜 LLM은 문자열을 뒤집는 것 같은 매우 간단한 문자열 처리 작업을 할 수 없나요? 토큰화.
- 왜 LLM은 영어가 아닌 언어(예: 일본어)에 약할까요? 토큰화.
- 왜 LLM은 간단한 산술 연산을 잘하지 못하나요? 토큰화.
- 왜 GPT-2는 Python 코드 작성에 불필요한 어려움을 겪었나요? 토큰화.
- 왜 내 LLM은 "<endoftext>"라는 문자열을 만나면 갑자기 멈추나요? 토큰화.
- 왜 "후행 공백(trailing whitespace)"에 대한 이상한 경고가 뜨나요? 토큰화.
- 왜 LLM이 "SolidGoldMagikarp"에 대해 물어보면 깨지나요? 토큰화.
- 왜 LLM을 사용할 때 JSON 대신 YAML을 선호해야 하나요? 토큰화.
- 왜 LLM은 실제로는 E2E 언어 모델링이 아닌가요? 토큰화.
- 고통의 진짜 근원은 무엇인가요? 토큰화.

LLM의 신뢰성을 개선하려면 이러한 모델을 어떻게 프롬프트해야 하는지 이해하는 것이 중요하며, 이는 모델의 한계를 이해하는 것과도 관련이 있습니다. 추론 시 `max_tokens` 설정 외에는 토크나이저에 대해 특별히 중점을 두지 않지만, 좋은 프롬프트 엔지니어링은 프롬프트를 구성하거나 형식을 지정하는 방식처럼 토큰화에서 고유하게 발생하는 제약과 한계를 이해하는 것과 관련이 있습니다. 예를 들어, 약어나 개념을 정확하게 처리하지 못하거나 토큰화하지 않아 프롬프트가 제대로 작동하지 않는 경우가 있을 수 있습니다. 이는 많은 LLM 개발자와 연구자들이 간과하는 매우 흔한 문제입니다.

토큰화에 유용한 도구로는 [Tiktokenizer](https://tiktokenizer.vercel.app/)가 있으며, 이 도구는 강의에서 시연 목적으로 실제로 사용됩니다.



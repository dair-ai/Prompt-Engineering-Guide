# 风险和误用

import { Callout } from 'nextra-theme-docs'

我们已经看到了如何使用few-shot学习和链式思考提示等技术来完成各种任务，有效的精心制作的提示是多么的有效。当我们考虑在LLMs之上构建实际应用程序时，思考与语言模型相关的误用、风险和安全实践变得至关重要。

本节重点介绍了通过提示注入等技术来突出LLMs的一些风险和误用。它还强调了有害行为以及如何通过有效的提示技术来潜在地减轻它们。其他感兴趣的主题包括泛化能力、校准、偏见、社会偏见和事实性等等。

<Callout emoji="⚠️">
  本节正在积极开发中。
</Callout>
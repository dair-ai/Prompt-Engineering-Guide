# Генерация, дополненная выборкой (Retrieval Augmented Generation, RAG)

import {Cards, Card} from 'nextra-theme-docs'
import {TerminalIcon} from 'components/icons'
import {CodeIcon} from 'components/icons'
import {Screenshot} from 'components/screenshot'
import RAG from '../../img/rag.png'

Языковые модели общего назначения можно дообучить, чтобы они лучше справлялись с такими задачами как сентимент-анализ (анализ эмоциональной окраски текста) и распознавание именованных сущностей. Как правило, такие задачи не требуют дополнительных фоновых знаний.

Для выполнения более сложных задач (или требующих большего объема знаний) можно построить систему, основанную на языковой модели, которая бы обращалась к внешнему источнику информации при обработке запроса. Такой подход обеспечивает большую фактическую достоверность, повышает надежность сгенерированных ответов и уменьшает вероятность появления галлюцинаций.

Исследователи из Мета AI предложили метод для работы с большими объемами информации и назвали его [Генерация, дополненная выборкой (Retrieval Augmented Generation, RAG)](https://ai.facebook.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/). Подход RAG объединяет поиск информации и модель, генерирующую текст. Модель, реализованную на основе такого подхода (далее RAG-модель), можно тонко настроить, и ее внутренняя база знаний будет изменена, поэтому не будет необходимости переучивать всю модель заново.

RAG-модель принимает входной запрос и извлекает нужные материалы из указанного источника (например, из Википедии). Затем эти материалы конкатенируются —это будет контекст для модели — с промптом входного запроса и передаются в генератор, который формирует ответ. Благодаря этому RAG-модель лучше подходит в ситуациях, когда фактические данные меняются со временем. Этот подход дает существенное преимущество, т.к. параметры базы знаний LLM статичны. Подход RAG позволяет языковым моделям избежать повторного обучения. Благодаря доступу к свежей информации модель может генерировать надежный ответ с помощью генерации, основанной на выборке.

В 2021 г. Льюис и др. представили обобщенную инструкцию по тонкой настройке для применения подхода RAG. Предобученная модель seq2seq используется в качестве параметрической памяти, а плотный векторный индекс Википедии – в качестве непараметрической (доступ осуществляется с помощью нейронного предобученного ретривера). Вот как работает такой подход:

<Screenshot src={RAG} alt="RAG" />
Источник изображения: [Льюис и др., 2021 г.](https://arxiv.org/pdf/2005.11401.pdf) 

RAG-модель показывает хорошие результаты при тестировании на [Natural Questions](https://ai.google.com/research/NaturalQuestions), [WebQuestions](https://paperswithcode.com/dataset/webquestions) и CuratedTrec. При тестировании на вопросах из датасетов MS-MARCO и Jeopardy, RAG-модель отвечает конкретнее, разнообразнее и с большей фактической точностью. RAG-модель также показывает более точные результаты при проверке фактов по FEVER.

RAG-подход может значительно улучшить ответы языковых моделей в задачах, требующих обработки большого количества информации и наличия экспертных знаний.

Подходы на основе ретриверов становятся все более распространенными и в сочетании с известными LLM (например, ChatGPT) расширяют возможности последних и повышают их фактологическую точность.

# Применение RAG: Генерация заголовков статей (ML-friendly)

Ниже мы подготовили руководство, в котором рассказывается об использовании LLM с открытым кодом для построения RAG-систем, генерирующих краткие и точные заголовки:

<Cards>
    <Card
    icon={<CodeIcon/>}
    title="Getting Started with RAG"
    href="https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/notebooks/pe-rag.ipynb"
    />
</Cards>

# Ссылки

- [Retrieval-Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2312.10997) (Декабрь 2023)
- [Retrieval Augmented Generation: Streamlining the creation of intelligent natural language processing models](https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/) (Сентябрь 2020)

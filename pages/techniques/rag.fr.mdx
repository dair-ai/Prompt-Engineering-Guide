# G√©n√©ration Augment√©e par R√©cup√©ration (RAG)

En anglais : "Retrieval Augmented Generation", commun√©ment abr√©g√© en RAG


import {Cards, Card} from 'nextra-theme-docs'
import {TerminalIcon} from 'components/icons'
import {CodeIcon} from 'components/icons'
import {Screenshot} from 'components/screenshot'
import RAG from '../../img/rag.png'
import { Callout } from 'nextra/components'

Les mod√®les de langage polyvalents peuvent √™tre affin√©s pour r√©aliser plusieurs t√¢ches courantes telles que l'analyse de sentiments et la reconnaissance d'entit√©s nomm√©es. Ces t√¢ches ne n√©cessitent g√©n√©ralement pas de connaissances suppl√©mentaires.

Pour des t√¢ches plus complexes et exigeantes en connaissances, il est possible de construire un syst√®me bas√© sur un mod√®le de langage qui acc√®de √† des sources de connaissances externes pour compl√©ter les t√¢ches. Cela permet une plus grande coh√©rence factuelle, am√©liore la fiabilit√© des r√©ponses g√©n√©r√©es et aide √† att√©nuer le probl√®me des "hallucinations".

Les chercheurs de Meta AI ont introduit une m√©thode appel√©e G√©n√©ration Augment√©e par R√©cup√©ration (RAG) pour aborder de telles t√¢ches exigeantes en connaissances. RAG combine un composant de r√©cup√©ration d'informations avec un mod√®le g√©n√©rateur de texte. RAG peut √™tre affin√© et ses connaissances internes peuvent √™tre modifi√©es de mani√®re efficace et sans n√©cessiter une reformation compl√®te du mod√®le.

RAG prend une entr√©e et r√©cup√®re un ensemble de documents pertinents/supportants donn√©s par une source (par exemple, Wikip√©dia). Les documents sont concat√©n√©s comme contexte avec la demande d'entr√©e originele et fournis au g√©n√©rateur de texte qui produit la sortie finale. Cela rend le RAG adaptable pour des situations o√π les faits pourraient √©voluer avec le temps. Cela est tr√®s utile car la connaissance param√©trique des LLM est statique. le RAG permet aux mod√®les de langage de contourner la reformation, permettant l'acc√®s aux informations les plus r√©centes pour g√©n√©rer des sorties fiables via la g√©n√©ration bas√©e sur la r√©cup√©ration.

Lewis et al., (2021) ont propos√© une recette de raffinement polyvalente pour le RAG. Un mod√®le seq2seq pr√©-entra√Æn√© est utilis√© comme m√©moire param√©trique et un index vectoriel dense de Wikip√©dia est utilis√© comme m√©moire non param√©trique (acc√©d√©e √† l'aide d'un r√©cup√©rateur pr√©-entra√Æn√© par r√©seau de neurones). Voici un aper√ßu de la fa√ßon dont l'approche fonctionne :

<Screenshot src={RAG} alt="RAG" />
Source de l'image : [Lewis et el. (2021)](https://arxiv.org/pdf/2005.11401.pdf)
Un RAG est performant sur plusieurs benchmarks tels que Natural Questions, WebQuestions, et CuratedTrec. Le RAG g√©n√®re des r√©ponses plus factuelles, sp√©cifiques et diversifi√©es lorsqu'il est test√© sur des questions MS-MARCO et Jeopardy. le RAG am√©liore √©galement les r√©sultats sur la v√©rification des faits FEVER.

Cela montre le potentiel de RAG comme une option viable et pertinente pour am√©liorer les sorties des mod√®les de langage dans des t√¢ches exigeantes en connaissances.

Plus r√©cemment, ces approches bas√©es sur la r√©cup√©ration sont devenues plus populaires et sont combin√©es avec des LLM bien connus comme ChatGPT pour am√©liorer les capacit√©s et la coh√©rence factuelle.

## Cas d'utilisation d'un RAG : G√©n√©rer des titres d'articles de machine learning facilement.
Ci-dessous, nous avons pr√©par√© un tutoriel afin de montrer l'utilisation de LLM open-source pour construire un syst√®me RAG pour g√©n√©rer des titres courts et concis d'articles sur l'apprentissage automatique :

<Cards>
    <Card
    icon={<CodeIcon />}
    title="Commencer avec un RAG"
    href="https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/notebooks/pe-rag.ipynb"
    />
</Cards>
<Callout type= "info" emoji="üéì">
  Vous voulez en savoir plus sur le RAG ? D√©couvrez notre [nouveau cours bas√© sur des cohortes](https://maven.com/dair-ai/prompt-engineering-llms?cohortSlug=). Utilisez le code promo MAVENAI20 pour une r√©duction de 20%.
</Callout>
## R√©f√©rences
(en fran√ßais en dessous)
- [Retrieval-Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2312.10997) (Dec 2023)
FR : [G√©n√©ration Augment√©e par R√©cup√©ration pour les Grands Mod√®les de Langage : Une synth√®se (document EN)](https://arxiv.org/abs/2312.10997) (D√©c 2023)

- [Retrieval Augmented Generation: Streamlining the creation of intelligent natural language processing models](https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/) (Sep 2020)
FR : [G√©n√©ration Augment√©e par R√©cup√©ration : Rationaliser la cr√©ation de mod√®les de traitement naturel du langage intelligents (doc EN)](https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/) (Sep 2020)

# 零样本提示

import {Bleed} from 'nextra-theme-docs'

如今，经过大量数据训练并调整指令的LLM能够执行零样本任务。我们在前一节中尝试了一些零样本示例。以下是我们使用的一个示例：

<iframe width="100%"
  height="415px"
  src="https://www.youtube.com/embed/ZTaHqdkxUMs?si=EDLjgAxuFxFcrSM3" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
  />

如今的大型语言模型(LLMs)，如 GPT-3.5 Turbo, GPT-4 和 Claude 3，都经过了调整以遵循指令，并在大量数据上进行了训练。大规模训练使这些模型能够以“零样本提示”的方式执行某些任务。零样本提示意味着用于与模型交互的提示不包含任何实际示例或演示，而直接指示模型执行任务，无需任何其他示例来引导它。

在上一节中，我们尝试了几个零样本示例。下面是我们使用的示例之一（即文本分类）：

*提示：*
```
将文本分类为中性、负面或正面。

文本：我认为这次假期还可以。
情感：
```

*输出：*
```
中性
```

请注意，在上面的提示中，我们没有向模型提供任何示例——这就是零样本能力的作用。

指令调整已被证明可以改善零样本学习[Wei等人（2022）](https://arxiv.org/pdf/2109.01652.pdf)。指令调整本质上是在通过指令描述的数据集上微调模型的概念。此外，[RLHF](https://arxiv.org/abs/1706.03741)（来自人类反馈的强化学习）已被采用以扩展指令调整，其中模型被调整以更好地适应人类偏好。这一最新发展推动了像ChatGPT这样的模型。我们将在接下来的章节中讨论所有这些方法和方法。

当零样本不起作用时，建议在提示中提供演示或示例，这就引出了少样本提示。在下一节中，我们将演示少样本提示。

# Создание цепочек промптов

import {Screenshot} from 'components/screenshot'
import PC1 from '../../img/prompt_chaining/prompt-chaining-1.png'

## Введение в Создание цепочек промптов

Для повышения надежности и производительности LLM, одним из важных приемов промпт-инжиниринга является разбиение задачи на подзадачи. После того как эти подзадачи определены, для LLM предлогаются подзадачи, а затем ее ответ используется в качестве входных данных для другого запроса. Это то, что называется Создание цепочек промптов, когда задача разбивается на подзадачи с целью создания цепочки операций промптов.

Создание цепочек промтов полезно для решения сложных задач, которые LLM может с трудом решить, если будет предложен очень большой промпт. При создание цепочки промптов, цепочки промптов выполняют преобразования или дополнительные процессы над сгенерированными ответами, прежде чем достичь конечного желаемой формы.

Помимо повышения производительности, цепочки промптов помогают повысить прозрачность вашего применения LLM, повышает управляемость и надежность. Это означает, что вы можете гораздо проще отлаживать проблемы с ответами модели, а также анализировать и улучшать производительность на различных этапах, которые нуждаются в улучшении.

Цепочка промптов особенно полезна при создании диалоговых помощников на базе LLM и улучшении персонализации и пользовательского опыта ваших приложений.

## Случаи использования Создания цепочек промптов

### Создание цепочек промптов для контроля качества документа

Цепочки промптов могут использоваться в различных сценариях, которые могут включать несколько операций или преобразований. Например, один из распространенных вариантов использования LLM предполагает ответы на вопросы о большом текстовом документе.

Вам поможет, если вы создадите два разных промпта, где первый промпт отвечает за извлечение соответствующих цитат для ответа на вопрос, а второй промпт принимает в качестве входных данных цитаты и исходный документ для ответа на заданный вопрос. Другими словами, вы создадите две разных промпта для выполнения ответа на вопрос о документе.

Первый промпт ниже извлекает соответствующие цитаты из документа, заданного в вопросе. Обратите внимание, что для простоты мы добавили заполнитель для документа `{{document}}`. Чтобы протестировать подсказку, вы можете скопировать и вставить статью из Википедии, например, эту страницу, посвященную [технике подсказок](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B0_%D0%BF%D0%BE%D0%B4%D1%81%D0%BA%D0%B0%D0%B7%D0%BE%D0%BA). Из-за более большого контекста, используемого для этой задачи, мы используем модель `gpt-4-1106-preview` от OpenAI. Вы можете использовать промты с длинным контекстом с другими LLM, такими как Claude.

Prompt 1: 
```
You are a helpful assistant. Your task is to help answer a question given a document. The first step is to extract quotes relevant to the question from the document, delimited by ####. Please output the list of quotes using <quotes></quotes>. Respond with "No relevant quotes found!" if no relevant quotes were found.


####
{{document}}
####
```

Вот скриншот всего промпта, включая вопрос, который передается с использованием роли `пользователя`.

<Screenshot src={PC1} alt="Prompt Chaining Part 1" />

Output of Prompt 1:
```
<quotes>
- Chain-of-thought (CoT) prompting[27]
- Generated knowledge prompting[37]
- Least-to-most prompting[38]
- Self-consistency decoding[39]
- Complexity-based prompting[41]
- Self-refine[42]
- Tree-of-thought prompting[43]
- Maieutic prompting[45]
- Directional-stimulus prompting[46]
- Textual inversion and embeddings[59]
- Using gradient descent to search for prompts[61][62][63][64]
- Prompt injection[65][66][67]
</quotes>
```

Цитаты, возвращенные в первом промпте, теперь можно использовать в качестве входных данных для второго промпта ниже. Обратите внимание, что вы можете еще немного очистить цитаты, то есть удалить цитаты. Эти цитаты можно удалить или использовать как часть другой подсказки в цепочке, но пока мы это проигнорируем.

Затем второй промпт берет соответствующие цитаты, извлеченные с помощью промпта 1, и готовит ответ на вопрос с учетом документа и извлеченных цитат. Второй промпт может быть следующим:

Output of Prompt 2:

```
The prompting techniques mentioned in the document include:

1. Chain-of-thought (CoT) prompting[27]
2. Generated knowledge prompting[37]
3. Least-to-most prompting[38]
4. Self-consistency decoding[39]
5. Complexity-based prompting[41]
6. Self-refine[42]
7. Tree-of-thought prompting[43]
8. Maieutic prompting[45]
9. Directional-stimulus prompting[46]
10. Textual inversion and embeddings[59]
11. Using gradient descent to search for prompts[61][62][63][64]
12. Prompt injection[65][66][67]

Each of these techniques employs unique strategies to enhance or specify the interactions with large language models to produce the desired outcomes.
```

Как видите, упрощение и создание цепочек промптов — это полезный подход к промптам, когда ответы необходимо подвергнуть нескольким операциям или преобразованиям. В качестве упражнения вы можете создать промпт, который удаляет цитаты (например, [27]) из ответа, прежде чем отправлять его в качестве окончательного ответа пользователю вашего приложения.

В этой [документации](https://docs.anthropic.com/claude/docs/prompt-chaining) вы также можете найти дополнительные примеры цепочек подсказок, в которых используется Claude LLM. Наш пример вдохновлен и заимствован из их примеров.

# Automatic Prompt Engineer (APE)

import { Callout, FileTree } from 'nextra-theme-docs'
import {Screenshot} from 'components/screenshot'
import APE from '../../img/APE.png'
import APECOT from '../../img/ape-zero-shot-cot.png'

<Screenshot src={APE} alt="APE" />
Fonte immagine: [Zhou et al., (2022)](https://arxiv.org/abs/2211.01910)

[Zhou et al., (2022)](https://arxiv.org/abs/2211.01910) propone automatic prompt engineer (APE), un framework per la generazione e la selezione automatica delle istruzioni. Il problema della generazione delle istruzioni viene inquadrato come sintesi del linguaggio naturale e affrontato come un problema di ottimizzazione black-box che utilizza gli LLM per generare e ricercare le soluzioni candidate.

La prima fase coinvolge un modello linguistico di grandi dimensioni (come un modello di inferenza) a cui vengono fornite dimostrazioni in uscita per generare istruzioni candidate ad un certo compito. Queste soluzioni candidate guideranno la procedura di ricerca. Le istruzioni vengono eseguite utilizzando un modello di destinazione e poi l'istruzione pi√π appropriata viene selezionata in base ai punteggi di valutazione calcolati.

APE scopre un prompt zero-shot CoT migliore del prompt "Pensiamo passo dopo passo" progettato manualmente ([Kojima et al., 2022](https://arxiv.org/abs/2205.11916)).

Il prompt "Lavoriamo passo dopo passo per essere sicuri di avere la risposta giusta" suscita un ragionamento a catena e migliora le prestazioni nei benchmark MultiArith e GSM8K:

<Screenshot src={APECOT} alt="APECOT" />
Fonte immagine: [Zhou et al., (2022)](https://arxiv.org/abs/2211.01910)

Questa ricerca tratta un argomento importante legato al prompt engineering, ovvero l'idea di ottimizzare automaticamente i prompt. Anche se in questa guida non approfondiamo l'argomento, ecco alcuni documenti chiave se siete interessati:

- [Prompt-OIRL](https://arxiv.org/abs/2309.06553) - propone di utilizzare l'apprendimento per rinforzo inverso offline per generare prompt dipendenti dalla query.
- [OPRO](https://arxiv.org/abs/2309.03409) - introduce l'idea di utilizzare gli LLM per ottimizzare i prompt: lasciare che gli LLM "Facciano un respiro profondo" migliora le prestazioni sui problemi matematici.
- [AutoPrompt](https://arxiv.org/abs/2010.15980) - propone un approccio per la creazione automatica di suggerimenti per una serie di compiti diversi, basato sulla ricerca guidata dal gradiente.
- [Prefix Tuning](https://arxiv.org/abs/2101.00190) - un'alternativa leggera alla sintonizzazione fine che aggiunge un prefisso continuo addestrabile per i compiti NLG. 
- [Prompt Tuning](https://arxiv.org/abs/2104.08691) - propone un meccanismo per l'apprendimento di suggerimenti morbidi attraverso la retropropagazione.

# Prompt Chaining

import {Screenshot} from 'components/screenshot'
import PC1 from '../../img/prompt_chaining/prompt-chaining-1.png'
import { Callout } from 'nextra/components'

## Introducci√≥n al Encadenamiento de Prompts

<iframe width="100%" height="415px" src="https://www.youtube.com/embed/CKZC5RigYEc?si=EG1kHf83ceawWdHX" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowFullScreen />

Para mejorar la fiabilidad y el rendimiento de los modelos de lenguaje (LLMs), una de las t√©cnicas m√°s importantes de ingenier√≠a de prompts es dividir las tareas en subtareas. Una vez identificadas estas subtareas, se proporciona un prompt para cada una y la respuesta generada se usa como entrada para otro prompt. A este proceso se le conoce como encadenamiento de prompts, en el que una tarea se desglosa en subtareas para crear una cadena de operaciones de prompts.

El encadenamiento de prompts es √∫til para llevar a cabo tareas complejas que un modelo de lenguaje podr√≠a tener dificultades para resolver si se le proporciona un prompt demasiado detallado. En este m√©todo, los prompts encadenados realizan transformaciones o procesos adicionales en las respuestas generadas antes de alcanzar el resultado final deseado.

Adem√°s de mejorar el rendimiento, el encadenamiento de prompts ayuda a aumentar la transparencia de tu aplicaci√≥n basada en modelos de lenguaje, as√≠ como su control y fiabilidad. Esto facilita la depuraci√≥n de problemas en las respuestas del modelo y permite analizar y mejorar su rendimiento en distintas fases.

El encadenamiento de prompts es especialmente √∫til para desarrollar asistentes conversacionales basados en LLMs y mejorar la personalizaci√≥n y experiencia del usuario en tus aplicaciones.
<Callout type= "info" emoji="üéì"> Aprende m√°s sobre el encadenamiento de prompts y m√©todos avanzados de generaci√≥n de prompts en nuestros nuevos cursos de IA. [¬°√önete ahora!](https://dair-ai.thinkific.com/) </Callout> 

## Casos de Uso del Encadenamiento de Prompts
Encadenamiento de Prompts para Preguntas y Respuestas sobre Documentos

El encadenamiento de prompts se puede aplicar en diferentes escenarios que impliquen m√∫ltiples operaciones o transformaciones. Un caso de uso com√∫n en modelos de lenguaje es responder preguntas sobre un documento extenso. Para ello, es √∫til dise√±ar dos prompts distintos:

    Un primer prompt que extraiga citas relevantes del documento para responder la pregunta.

    Un segundo prompt que tome esas citas y el documento original para generar una respuesta adecuada.

En otras palabras, estar√°s creando dos prompts diferentes para responder una pregunta basada en un documento.

El primer prompt extrae las citas relevantes del documento seg√∫n la pregunta dada. Para simplificar, hemos a√±adido un marcador de posici√≥n para el documento `{{document}}`. Para probar este prompt, puedes copiar y pegar un art√≠culo de Wikipedia, como esta p√°gina sobre ingenier√≠a de prompts [prompt engineering](https://en.wikipedia.org/wiki/Prompt_engineering). Debido al amplio contexto necesario para esta tarea, utilizamos el modelo `gpt-4-1106-preview` de OpenAI, aunque puedes usar otros modelos de contexto largo, como Claude.

Prompt 1: 
```
You are a helpful assistant. Your task is to help answer a question given in a document. The first step is to extract quotes relevant to the question from the document, delimited by ####. Please output the list of quotes using <quotes></quotes>. Respond with "No relevant quotes found!" if no relevant quotes were found.


####
{{document}}
####
```

Aqu√≠ tienes una captura de pantalla de todo el prompt, incluida la pregunta que se pasa usando el rol de `user`.

<Screenshot src={PC1} alt="Prompt Chaining Part 1" />

Salida del Prompt 1:
```
<quotes>
- Chain-of-thought (CoT) prompting[27]
- Generated knowledge prompting[37]
- Least-to-most prompting[38]
- Self-consistency decoding[39]
- Complexity-based prompting[41]
- Self-refine[42]
- Tree-of-thought prompting[43]
- Maieutic prompting[45]
- Directional-stimulus prompting[46]
- Textual inversion and embeddings[59]
- Using gradient descent to search for prompts[61][62][63][64]
- Prompt injection[65][66][67]
</quotes>
```

Las citas obtenidas en el primer prompt ahora pueden usarse como entrada para el segundo prompt a continuaci√≥n. Ten en cuenta que puedes limpiar un poco m√°s las citas, por ejemplo, eliminando las referencias. Estas referencias podr√≠an eliminarse o utilizarse como parte de otro prompt en la cadena, pero puedes ignorar esto por ahora. El segundo prompt toma las citas relevantes extra√≠das por el primer prompt y prepara una respuesta √∫til a la pregunta basada en el documento y en esas citas extra√≠das. El segundo prompt puede ser el siguiente:

Prompt 2:
```
Given a set of relevant quotes (delimited by <quotes></quotes>) extracted from a document and the original document (delimited by ####), please compose an answer to the question. Ensure that the answer is accurate, has a friendly tone, and sounds helpful.

####
{{document}}
####

<quotes>
- Chain-of-thought (CoT) prompting[27]
- Generated knowledge prompting[37]
- Least-to-most prompting[38]
- Self-consistency decoding[39]
- Complexity-based prompting[41]
- Self-refine[42]
- Tree-of-thought prompting[43]
- Maieutic prompting[45]
- Directional-stimulus prompting[46]
- Textual inversion and embeddings[59]
- Using gradient descent to search for prompts[61][62][63][64]
- Prompt injection[65][66][67]
</quotes>
```

Output of Prompt 2:

```
The prompting techniques mentioned in the document include:

1. Chain-of-thought (CoT) prompting[27]
2. Generated knowledge prompting[37]
3. Least-to-most prompting[38]
4. Self-consistency decoding[39]
5. Complexity-based prompting[41]
6. Self-refine[42]
7. Tree-of-thought prompting[43]
8. Maieutic prompting[45]
9. Directional-stimulus prompting[46]
10. Textual inversion and embeddings[59]
11. Using gradient descent to search for prompts[61][62][63][64]
12. Prompt injection[65][66][67]

Each of these techniques employs unique strategies to enhance or specify the interactions with large language models to produce the desired outcomes.
```

Como puedes ver, simplificar y crear cadenas de prompts es un enfoque √∫til cuando las respuestas necesitan pasar por varias operaciones o transformaciones. Como ejercicio, puedes dise√±ar un prompt que elimine las referencias (por ejemplo, [27]) de la respuesta antes de enviarla como respuesta final al usuario de tu aplicaci√≥n.

Tambi√©n puedes encontrar m√°s ejemplos de encadenamiento de prompts en esta [documentation](https://docs.anthropic.com/claude/docs/prompt-chaining) que utiliza el modelo Claude. Nuestro ejemplo est√° inspirado y adaptado de sus ejemplos.

# Tools & Libraries

#### (Sorted by Name)

| Tool/Library | Description |
| :----------- | :---------- |
| [ActionSchema](https://actionschema.com) | Framework for structured description of AI agent actions |
| [Agenta](https://github.com/Agenta-AI/agenta) | Platform for deploying, testing and monitoring LLM applications |
| [AI Test Kitchen](https://aitestkitchen.withgoogle.com) | Google's experimental platform for testing AI models |
| [AnySolve](https://www.anysolve.ai) | Tool for automated task solving using LLMs |
| [AnythingLLM](https://github.com/Mintplex-Labs/anything-llm) | Personalized LLM chatbot with RAG capabilities |
| [betterprompt](https://github.com/stjordanis/betterprompt) | Library for prompt optimization and LLM response improvement |
| [Chainlit](https://github.com/chainlit/chainlit) | Framework for building chat interfaces for LLM applications |
| [ChatGPT Prompt Generator](https://huggingface.co/spaces/merve/ChatGPT-prompt-generator) | Tool for generating ChatGPT prompts |
| [ClickPrompt](https://github.com/prompt-engineering/click-prompt) | Visual prompt builder for LLMs |
| [DreamStudio](https://beta.dreamstudio.ai) | Official interface for Stable Diffusion image generation |
| [Dify](https://dify.ai/) | Platform for deploying and managing LLM applications |
| [DUST](https://dust.tt) | Tool for deploying and monitoring LLMs in production |
| [Dyno](https://trydyno.com) | Platform for creating and managing AI agents |
| [EmergentMind](https://www.emergentmind.com) | Tool for code analysis and generation using LLMs |
| [EveryPrompt](https://www.everyprompt.com) | Library for A/B testing prompts |
| [FlowGPT](https://flowgpt.com) | Community platform for sharing prompts |
| [fastRAG](https://github.com/IntelLabs/fastRAG) | Optimized framework for RAG applications |
| [Google AI Studio](https://ai.google.dev/) | Google's tool for working with Gemini and other AI models |
| [Guardrails](https://github.com/ShreyaR/guardrails) | Library for validating and controlling LLM outputs |
| [Guidance](https://github.com/microsoft/guidance) | Framework for deterministic control of LLM outputs |
| [GPT Index](https://github.com/jerryjliu/gpt_index) | Original name for LlamaIndex (data indexing for LLMs) |
| [GPTTools](https://gpttools.com/comparisontool) | Set of utilities for working with GPT models |
| [hwchase17/adversarial-prompts](https://github.com/hwchase17/adversarial-prompts) | Collection of adversarial prompts for LLM testing |
| [Interactive Composition Explorer](https://github.com/oughtinc/ice) | Tool for interactive complex prompt creation |
| [Knit](https://promptknit.com) | Platform for creating and managing LLM workflows |
| [LangBear](https://langbear.runbear.io) | Simplified interface for LangChain |
| [LangChain](https://github.com/hwchase17/langchain) | Framework for building LLM chains with external data |
| [LangSmith](https://docs.smith.langchain.com) | Debugging and monitoring tool for LLM applications |
| [Lexica](https://lexica.art) | Search engine for Stable Diffusion prompts/images |
| [LMFlow](https://github.com/OptimalScale/LMFlow) | Framework for LLM fine-tuning and deployment |
| [LM Studio](https://lmstudio.ai/) | Desktop app for running LLMs locally |
| [loom](https://github.com/socketteer/loom) | Tool for recording LLM interactions |
| [Metaprompt](https://metaprompt.vercel.app/?task=gpt) | Library for creating and managing meta-prompts |
| [ollama](https://github.com/jmorganca/ollama) | Tool for local LLM execution |
| [OpenAI Playground](https://beta.openai.com/playground) | Web interface for OpenAI model experimentation |
| [OpenICL](https://github.com/Shark-NLP/OpenICL) | Framework for in-context learning with LLMs |
| [OpenPrompt](https://github.com/thunlp/OpenPrompt) | Library for prompt templates and management |
| [OpenPlayground](https://nat.dev/) | Alternative interface for testing various LLMs |
| [OptimusPrompt](https://www.optimusprompt.ai) | Tool for prompt optimization |
| [Outlines](https://github.com/normal-computing/outlines) | Library for controlled text generation |
| [Playground](https://playgroundai.com) | General term for LLM testing environments |
| [Portkey AI](https://portkey.ai/) | Platform for LLM request management and analysis |
| [Prodia](https://app.prodia.com/#/) | API for Stable Diffusion image generation |
| [Prompt Apps](https://chatgpt-prompt-apps.com/) | Ready-made mini-applications based on prompts |
| [PromptAppGPT](https://github.com/mleoking/PromptAppGPT) | Framework for GPT-based applications |
| [Prompt Base](https://promptbase.com) | Marketplace for buying/selling prompts |
| [PromptBench](https://github.com/microsoft/promptbench) | Library for prompt benchmarking |
| [Prompt Engine](https://github.com/microsoft/prompt-engine) | Tool for structured prompt generation |
| [prompted.link](https://prompted.link) | Database of prompts for various tasks |
| [Prompter](https://prompter.engineer) | Utility for prompt formatting |
| [PromptInject](https://github.com/agencyenterprise/PromptInject) | Framework for prompt injection testing |
| [Prompts.ai](https://github.com/sevazhidkov/prompts-ai) | Platform for collaborative prompt work |
| [Promptmetheus](https://promptmetheus.com) | Tool for prompt effectiveness analysis |
| [PromptPerfect](https://promptperfect.jina.ai/) | Service for task-specific prompt optimization |
| [Promptly](https://trypromptly.com/) | Library for rapid LLM prototyping |
| [PromptSource](https://github.com/bigscience-workshop/promptsource) | Collection of ready-made prompts |
| [PromptTools](https://github.com/hegelai/prompttools) | Set of prompt testing and debugging tools |
| [Scale SpellBook](https://scale.com/spellbook) | Platform for prompt engineering projects |
| [sharegpt](https://sharegpt.com) | Service for sharing ChatGPT conversations |
| [SmartGPT](https://getsmartgpt.com) | Tool for improving GPT responses via multi-step reasoning |
| [ThoughtSource](https://github.com/OpenBioLink/ThoughtSource) | Library for analyzing LLM reasoning chains |
| [Visual Prompt Builder](https://tools.saxifrage.xyz/prompt) | Tool for visual prompt creation (e.g., for image generation) |
| [Wordware](https://www.wordware.ai) | Platform for creating and managing LLM workflows |
| [YiVal](https://github.com/YiVal/YiVal) | Tool for LLM output validation and evaluation |

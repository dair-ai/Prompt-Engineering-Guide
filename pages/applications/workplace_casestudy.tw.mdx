# 應屆畢業生職務分類案例研究

[Clavié 等人，2023](https://arxiv.org/abs/2303.07142) 提供了一個針對在生產環境中中等規模的文字分類用例應用提示詞工程的案例研究。他們使用「該工作是否適合應屆畢業生」這個問題作為任務，評估了多種提示詞工程技巧，並報告使用 GPT-3.5（`gpt-3.5-turbo`）得出的結果。

這項研究表明，LLM 在所有測試的模型中表現最佳，包括一個強力的基準模型 DeBERTa-V3。`gpt-3.5-turbo` 在所有主要指標上也明顯優於先前版本的 GPT3，但需進行更多的輸出解析，因為它在遵循樣板方面的表現似乎不如其他版本。

這次提示詞工程方法的主要發現如下：

- 對於不需要專業知識的任務，少量示例（Few-shot CoT）提示詞比零示例（Zero-shot）提示詞的表現更差。
- 提示詞對正確推理的影響極大。只要求模型分類給定的工作，其 F1 分數即為 65.6，而經過提示詞工程最佳化後，模型的 F1 分數達到了 91.7。
- 嘗試強迫模型遵循樣板在所有情況下都會降低效能（這一行為在後來對 GPT-4 的早期測試中消失）。
- 許多小變更對效能有著超乎預期的影響。
  - 下面的表格展示了所有經過測試的修改。
  - 正確提供指令並重申關鍵點似乎是最大的效能推動因素。
  - 就算只是給模型一個（人類）名字並用該名字稱呼它，也能提高 F1 分數 0.6 點。

### 經過測試的提示詞修改

| 簡稱       | 說明                                                                      |
|-----------|---------------------------------------------------------------------|
| Baseline  | 提供一份職位招募資訊並詢問它是否適合畢業生。                       |
| CoT       | 在查詢之前給出幾個準確分類的示例。                                 |
| Zero-CoT  | 要求模型逐步推理後再給出答案。                                     |
| rawinst   | 透過加到使用者訊息中來給出關於其角色和任務的說明。                 |
| sysinst   | 作為系統訊息給出關於其角色和任務的說明。                           |
| bothinst  | 將角色作為系統訊息和任務作為使用者訊息拆分說明。                   |
| mock      | 透過模擬討論來給出任務說明，其中模型確認了它們。                   |
| reit      | 透過重複強調關鍵要素來加強說明。                                   |
| strict    | 要求模型嚴格按照給定的樣板回答。                                   |
| loose     | 要求只根據給定樣板給出最終答案。                                   |
| right     | 要求模型得出正確的結論。                                                  |
| info      | 提供額外資訊以解決常見的推理失敗。                                         |
| name      | 給模型一個名字，然後在對話中用這個名字稱呼它。                             |
| pos       | 在向模型發問前，提供正面的回饋。                                         |

### 所有提示詞修改的效能影響

|                                        | 精確度         | 召回率         | F1 分數        | 樣板黏著度              |
|----------------------------------------|---------------|---------------|---------------|------------------------|
| _Baseline_                             | _61.2_        | _70.6_        | _65.6_        | _79%_                  |
| _CoT_                                  | _72.6_        | _85.1_        | _78.4_        | _87%_                  |
| _Zero-CoT_                             | _75.5_        | _88.3_        | _81.4_        | _65%_                  |
| _+rawinst_                             | _80_          | _92.4_        | _85.8_        | _68%_                  |
| _+sysinst_                             | _77.7_        | _90.9_        | _83.8_        | _69%_                  |
| _+bothinst_                            | _81.9_        | _93.9_        | _87.5_        | _71%_                  |
| +bothinst+mock                         | 83.3          | 95.1          | 88.8          | 74%                    |
| +bothinst+mock+reit                    | 83.8          | 95.5          | 89.3          | 75%                    |
| _+bothinst+mock+reit+strict_           | _79.9_        | _93.7_        | _86.3_        | _**98%**_              |
| _+bothinst+mock+reit+loose_            | _80.5_        | _94.8_        | _87.1_        | _95%_                  |
| +bothinst+mock+reit+right              | 84            | 95.9          | 89.6          | 77%                    |
| +bothinst+mock+reit+right+info         | 84.9          | 96.5          | 90.3          | 77%                    |
| +bothinst+mock+reit+right+info+name    | 85.7          | 96.8          | 90.9          | 79%                    |
| +bothinst+mock+reit+right+info+name+pos| **86.9**      | **97**        | **91.7**      | 81%                    |

"Template stickiness" 指的是模型有多頻繁地按照所期望的格式作答。

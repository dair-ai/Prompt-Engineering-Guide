# 在LLM中调用函数

import {Cards, Card, Callout} from 'nextra-theme-docs'
import {CodeIcon} from 'components/icons'

## 调用函数

<iframe width="100%"
  height="415px"
  src="https://www.youtube.com/embed/p0I-hwZSWMs?si=tQgi-LiHe6Oj_rzm" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
  />


函数调用是指可靠地连接LLM与外部工具的能力。让用户能够使用高效的外部工具、与外部API进行交互。

GPT-4和GPT-3.5是经过微调的LLM，能够检测函数是否被调用，随后输出包含调用函数参数的JSON。通过这一过程被调用的函数能够作为工具添加到您的AI应用中，并且您可以在单个请求中定义多个函数。

函数调用是一项重要能力。它对于构建LLM驱动的聊天机器人或代理至关重要。这些聊天机器人或代理需要为LLM检索上下文。它们还与外部工具交互。这种交互是通过将自然语言转换为API调用来完成的。

函数调用使开发者能够创建：

- 能够高效使用外部工具回答问题的对话代理。例如，查询“伯利兹的天气如何？”将被转换为类似`get_current_weather(location: string, unit: 'celsius' | 'fahrenheit')`的函数调用
- 用于提取和标记数据的LLM驱动解决方案（例如，从维基百科文章中提取人名）
- 可以帮助将自然语言转换为API调用或有效数据库查询的应用程序
- 能够与知识库交互的对话式知识检索引擎

在这份指南中，我们展示了如何针对GPT-4和其他开源模型给出提示，以执行不同的函数调用。

## 使用GPT-4进行函数调用

作为一个基本示例，假设我们要求模型检查特定地点的天气。

LLM本身无法响应此请求。因为它所使用的训练数据集截止至之前的某个日期。解决这个问题的方法是将LLM与外部工具结合起来。您可以利用模型的函数调用能力来确定要调用的外部函数及其参数，然后让它返回最终回复结果。以下是一个简单的示例，展示了如何使用OpenAI API实现这一点。

假设一个用户向模型提出以下问题：

```
伦敦的天气如何？
```

要使用函数调用处理此请求，第一步是定义一个或一组天气函数。您将作为OpenAI API请求的一部分传递这些函数：

```python
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA",
                    },
                    "unit": {
                        "type": "string", 
                        "enum": ["celsius", "fahrenheit"]},
                },
                "required": ["location"],
            },
        },   
    }
]
```

`get_current_weather`函数能够返回指定位置的天气情况。当您将这个函数定义作为请求的一部分传递时，它实际上并不执行函数，只是返回一个包含调用函数所需参数的JSON对象。以下是一些如何实现这一点的代码片段。

您可以如下定义一个完整的函数：

```python
def get_completion(messages, model="gpt-3.5-turbo-1106", temperature=0, max_tokens=300, tools=None):
    response = openai.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
        tools=tools
    )
    return response.choices[0].message
```

您可以像这样构造用户提问：

```python
messages = [
    {
        "role": "user",
        "content": "伦敦的天气如何？"
    }
]
```

最后，您可以调用`get_completion`函数，将结果传递给`response`中的`messages`和`tools`：

```python
response = get_completion(messages, tools=tools)
```

`response`的构造如下所示：

```python
ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='...', function=Function(arguments='{"location":"London","unit":"celsius"}', name='get_current_weather'), type='function')])
```

特别地，`arguments` 对象包含了模型提取的重要参数，这些参数将被用于完成请求。

然后您可以调用一个外部天气API来获取实际的天气信息。一旦您有了天气信息，就可以将其传回模型，随后根据原始用户问题总结出最终回应。

## Notebooks

<Callout type= "info" emoji="🎓">
了解我们最新推出的人工智能课程中关于高级提示工程技术与最佳实践的内容。[立即加入!](https://dair-ai.thinkific.com/)
使用优惠码 PROMPTING20 可额外享受 20% 折扣优惠。
</Callout>

这里有一个[python notebook](https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/notebooks/pe-function-calling.ipynb) 提供了一个简单示例，展示了如何使用 OpenAI API 进行函数调用。

<Cards>
    <Card 
        icon={<CodeIcon />}
        title="使用 OpenAI APIs 进行函数调用"
        href="https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/notebooks/pe-function-calling.ipynb"
    />
</Cards>


## 使用开源LLM进行函数调用
更多使用开源LLM进行函数调用的说明即将推出...

## 函数调用用例

以下是函数调用能力在大语言模型（LLMs）中可带来显著益处的典型应用场景: 

- **对话代理系统**: 函数调用机制可用于构建复杂的对话代理或聊天机器人，使其能够通过调用外部 API 或知识库处理复杂查询，从而生成更具相关性与实用性的响应。

- **自然语言理解**: 可将自然语言转换为结构化的 JSON 数据，或从文本中提取结构化信息。被广泛应用于命名实体识别、情感分析及关键词提取等任务中。

- **数学问题求解**: 支持定义涵盖多种类型高阶计算的自定义函数以分步骤求解复杂数学问题，提升语言模型在数学推理方面的能力。

- **API 集成**: 函数调用有助于将大语言模型与外部 API 高效集成，模型根据输入生成有效的 API 请求，从而实现信息检索、自动问答或创意协助等功能。

- **信息抽取**: 从给定输入中提取特定信息，如从文章中获取相关新闻条目或参考资料，提升模型的实用性与精准性。


## 参考文献
- [Fireworks Raises the Quality Bar with Function Calling Model and API Release](https://blog.fireworks.ai/fireworks-raises-the-quality-bar-with-function-calling-model-and-api-release-e7f49d1e98e9)
- [Benchmarking Agent Tool Use and Function Calling](https://blog.langchain.dev/benchmarking-agent-tool-use/)
- [Function Calling](https://ai.google.dev/docs/function_calling)
- [Interacting with APIs](https://python.langchain.com/docs/use_cases/apis)
- [OpenAI's Function Calling](https://platform.openai.com/docs/guides/function-calling)
- [How to call functions with chat models](https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models)
- [Pushing ChatGPT's Structured Data Support To Its Limits](https://minimaxir.com/2023/12/chatgpt-structured-data/)
- [Math Problem Solving with Function Calling](https://github.com/svpino/openai-function-calling/blob/main/sample.ipynb)

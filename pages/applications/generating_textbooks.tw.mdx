# 應對合成資料集的多樣性問題

import {Screenshot} from 'components/screenshot'

import IMG1 from '../../img/synthetic_diversity/textbooks_1.png'
import IMG2 from '../../img/synthetic_diversity/textbooks_2.png'

在前一章的[說明](https://www.promptingguide.ai/applications/synthetic_rag)中，我們討論了如何使用 LLM 產生合成資料集，來進一步微調本機的檢索模型（Retriever）。那個方法仰賴一個大型未標註文件語料庫：對每份文件產生一個或多個合成查詢，形成「查詢－文件」配對。

但如果你的任務不是資訊檢索呢？
假設你要處理的是「法律文件分類」，而且因為合規與隱私限制，**無法將任何資料送往外部 API**。在這種情況下，你必須訓練本機模型，而資料蒐集會變成產品開發上最大的時間與成本瓶頸。

為了說明方便，我們先用「產生兒童故事」當例子。這也是 [Eldan et al. (2023)](https://arxiv.org/abs/2305.07759) 研究的出發點：
每個故事由 2–3 個段落組成，情節簡單、主題明確；整體語料則覆蓋兒童常見的詞彙與基礎知識。

自然語言不只是符號與規則，更是用來傳遞與解釋意義的媒介。
在用 LLM 產生訓練資料時，**最大挑戰之一就是「多樣性」**：就算把[產生溫度（generation temperature）](https://www.promptingguide.ai/introduction/settings)調得很高，模型仍可能不斷重複相似的模式，產生內容單一的資料集。除此之外，敘事的連貫性與語意相關性也都是產生任務的常見難題。

為了對抗這個問題，作者先準備了一份約 1500 個單詞的「兒童基本詞彙表」，並依名詞、動詞、形容詞分類。每次產生故事時：

- 隨機挑選 1 個動詞、1 個名詞、1 個形容詞
- 要求模型在故事中自然使用這些詞

這種做法有效地擴充了資料集涵蓋的概念組合，讓故事能遍佈整個詞彙空間，不再集中在少數常見主題上。作者還額外設計了一份「故事特徵」清單（例如是否包含對話、是否有情節反轉、是否是壞結局、是否帶有寓意等），每次隨機選取一小部分要求模型加進故事裡。

*Prompt 範例：*
```text
Write a short story (3-5 paragraphs) which only uses very simple words that a 3 year old child would likely understand. The story should use the verb ”{random.choice(verbs_list)}”, the noun ”{random.choice(nouns_list)}” and the adjective ”{random.choice(adjectives_list)}”. The story should have the following features: {random.choice(features_list)}, {random.choice(features_list)}. Remember to only use simple words!
```

假設隨機填入後變成：

*Prompt 範例：*
```text
Write a short story (3-5 paragraphs) which only uses very simple words that a 3 year old child would likely understand. The story should use the verb ”decorate”, the noun ”thunder” and the adjective ”ancient”. The story should have the following features: the story should contain at least one dialogue, the story has a bad ending. Remember to only use simple words!
```

*輸出（節錄）：*
```text
Once upon a time, in an ancient house, there lived a girl named Lily. She loved to decorate her room with pretty things. ...
```

這裡我們仰賴的是最新一代文字產生模型（如 GPT-3.5、GPT-4），請它們依照「帶有隨機化參數的提示詞」大量產生故事。
只要提示詞中的隨機組合足夠多，即便某些字相同，整體故事風格與內容也會大幅差異。
換句話說，**我們透過「隨機化 prompt」來注入多樣性**，讓輸出的合成資料集更加豐富。

整體做法可以抽象成四個步驟：

1. 找出在你的合成資料集中，各樣本之間「會變動」的參數或實體；
2. 產生或手工整理一組候選集合，用來填入這些空格；
3. 透過隨機挑選實體來產生資料集。建議把溫度設在預設值以上、但低於最大值；
4. 用 ChatGPT/GPT-4 的產生結果來訓練本機模型。

需要注意的是：用來當作合成資料起始條件的「實體」之一，也可以是分類標籤。例如，在情緒分類任務裡，你可以在 prompt 中直接寫明「positive」或「negative」，讓模型產出帶有對應標籤風格的文字；接著再用這些資料訓練本機分類器。

# 迭代式（階層式）合成資料產生

你也可以用更多實體把格式做得更複雜，其中有些實體可以先由 LLM 預先產出。舉例來說，你可以先請模型產出故事摘要，並寫下一句「必須出現在故事中的句子」；接著把這些中間資料放進最後的請求。

*Prompt:*
```
Summary: {a short summary generated by LLM, using the approach above}
Features: {copy the features from the initial prompt}
Sentence: {a sentence generated by LLM, which should be present in the story}
Words: {copy the words from the initial prompt}
Story:
```

填入後的 prompt 範例如下：

*Prompt:*
```
Summary: Lily and Timmy build a sandcastle together and learn to compromise, but it gets knocked over by a gust of wind. They find beauty in the broken sandcastle and play happily with a butterfly.
Features: Dialogue, Foreshadowing, Twist
Sentence: One day, she went to the park and saw a beautiful butterfly.
Words: disagree, network, beautiful
Story:
```

*Output:*
```
Once upon a time, there was a little girl named Lily. She loved to play with her toys and her friends. One day, she went to the park and saw a beautiful butterfly. She tried to catch it, but it flew away. Lily’s friend, Timmy, came to play with her. They decided to build a sandcastle, but they disagreed on how to build it. Lily wanted to make it tall, while Timmy wanted to make it wide. They argued for a while, but finally agreed to make it both tall and wide. As they were building the sandcastle, they noticed a group of ants working together. They realized that the ants were building a network of tunnels. Suddenly, a gust of wind came and knocked over their sandcastle. They were sad, but then they saw the butterfly again. It landed on the remains of their sandcastle and they realized that it was still beautiful, even in its broken state. They smiled and played together happily.
```

因此，你可以產生數十萬筆、甚至更多樣的樣本，拿來訓練模型。假設你想訓練一個分類器，用來判斷一段文字是否包含「對話」或「情節反轉」；只要初始 prompt 中包含了標籤，就能知道每個合成樣本對應的目標值應該是什麼。

# Textbooks Are All You Need

這個方向的一個關鍵問題是：資料集合成（synthesis）在真實世界的應用訓練上，是否真的能帶來效益？所幸作者在研究中也正面回答了這個問題，並驗證：使用由頂尖 LLM 產生的合成資料來訓練較小的語言模型，確實能帶來顯著效果。

在 [Gunasekar et al. (2023)](https://arxiv.org/abs/2306.11644) 的研究裡，作者強調「高品質訓練資料」的重要性。他們認為：如果語言模型能用更像「優質教科書」的材料來訓練——清楚、完整、具資訊性且不帶偏見——模型會更有效。

這些原則也成為建立半合成資料集的基礎，用來訓練名為 Phi-1 的 LLM。主要評估任務是：根據文字描述或 docstring 產生對應的 Python 函式，並以 HumanEval（[Chen et al., 2021](https://arxiv.org/abs/2107.03374)）做評測。

作者也指出，這個做法之所以需要多樣性，原因包括：

- 讓語言模型接觸到多種程式表達與解題方式
- 降低過度擬合或只依循特定模式的風險
- 提升處理陌生或創新任務的能力

為了處理寫程式這類挑戰，作者建立了類教科書式文件，聚焦在能促進推理與基礎演算法能力的主題。多樣性則是透過限制條件來達成，例如：

- 主題
- 目標讀者

可惜的是，論文並沒有提供用來產生合成資料的 prompt 樣板細節；但作者展示了成果樣貌。他們選擇用 ChatGPT（GPT-3.5）而非 GPT-4，即便如此，透過合成資料微調仍取得了非常好的成效。

<Screenshot src={IMG1} alt="Generated textbook-like sample" />

圖片來源：[Gunasekar et al. (2023)](https://arxiv.org/abs/2306.11644)

這裡特別值得注意的是「目標讀者」這個限制條件。指定目標讀者，是提升合成資料多樣性很有效的方法：高中生、資工大學生、博士候選人，在表達與吸收資訊方式上必然不同，產出的教材也會更豐富。下面嘗試重現這個 prompt：

*Prompt:*
```
Write an extract from a Computer Science textbook for a 1st-year bachelor. The coding language is Python 3.6.

This is an extract from the middle of the following topic: Singular matrices.

The extract starts with a high-level overview of the topic. Then, it presents an example and describes the solution in natural language. After that, it provides 1-2 code snippets, following the example. Each snippet has no more than 10 rows. There should be no text after code snippets.

Keep in mind that the extract should be concise and explain only one concept at a time.  The code should represent a Python function & its call. All the common ML/DS libraries are available.

Don't be too verbose. The expected length of the extract is 2 paragraphs at most.
```

*Output:*
```
**Singular Matrices**

In linear algebra, a matrix is termed as "singular" if it doesn't have an inverse. Another equivalent definition is when the determinant of the matrix is zero. Singular matrices are crucial because they represent systems of linear equations that do not have a unique solution.
In linear algebra, a matrix is termed as "singular" if it doesn't have an inverse. Another equivalent definition is when the determinant of the matrix is zero. Singular matrices are crucial because they represent systems of linear equations that do not have a unique solution.

Consider a 2x2 matrix `[[a, b], [c, d]]`. If the product of `ad` and `bc` is the same (i.e., `ad = bc`), then this matrix is singular. Let's explore this with an example: given the matrix `[[2, 4], [1, 2]]`, you'll find that the product of the diagonals yields the same result (2 * 2 = 4 * 1), thus it's a singular matrix.

import numpy as np

def is_singular(matrix):
    determinant = np.linalg.det(matrix)
    return abs(determinant) < 1e-9

matrix_example = np.array([[2, 4], [1, 2]])
print(is_singular(matrix_example))  # returns True
```

相當接近！

整體來看，作者約產生了 10 億個 token 的合成教材，拿來擴充訓練集，讓僅有 1.5B 參數的 Phi-1 在 HumanEval 等指標上能與體積大十倍的模型競爭（更多細節可參考 [Gunasekar et al. (2023)](https://arxiv.org/abs/2306.11644)）。

<Screenshot src={IMG2} alt="Phi-1 metrics, compared to bigger models." />

圖片來源：[Gunasekar et al. (2023)](https://arxiv.org/abs/2306.11644)

對你的任務來說，你可能不需要這麼大量的合成資料（因為作者研究的是預訓練，會需要大量資源）。不過，即便只做粗略估算：若以 `$0.002` / 1k tokens（ChatGPT 標準定價）計算，產生這些 token 的成本大約是 `$2000`，而 prompt 的成本也大概相近。

請記得：當領域越小眾、或語言偏離英文越多時，使用合成資料進行微調的價值通常越高。另外，這種方法也很適合搭配 [Chain-of-Thought（CoT）](https://www.promptingguide.ai/techniques/cot) 等推理提示詞技巧，幫助本機模型提升推理能力。其他提示詞技巧也同樣適用。最後，也別忘了許多開源模型（例如 Alpaca（[Taori et al., (2023)](https://crfm.stanford.edu/2023/03/13/alpaca.html)）與 Vicuna（[Zheng et al., (2023)](https://lmsys.org/blog/2023-03-30-vicuna/)））之所以表現亮眼，很大程度也來自於在合成資料上做微調。
